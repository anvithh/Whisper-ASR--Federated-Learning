{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "INSTALLING PACKAGES"
      ],
      "metadata": {
        "id": "Ox1FJsU-lVOI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OwpjqL5olPRI"
      },
      "outputs": [],
      "source": [
        "!pip install accelerate -U\n",
        "!pip install jiwer\n",
        "!pip install datasets\n",
        "!pip install lora\n",
        "!pip install torch\n",
        "!pip install evaluate\n",
        "!pip install peft"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "IMPORT LIBRARIES"
      ],
      "metadata": {
        "id": "2-ijc-F1lkik"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor, AdamW\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from tqdm import tqdm\n",
        "import csv\n",
        "import torchaudio\n",
        "from transformers import WhisperFeatureExtractor\n",
        "from transformers import WhisperTokenizer\n",
        "from transformers import WhisperProcessor\n",
        "from transformers import WhisperForConditionalGeneration"
      ],
      "metadata": {
        "id": "D7gbDGyElm7H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SET DEVICE"
      ],
      "metadata": {
        "id": "K739c24Rl12u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "metadata": {
        "id": "MuTMgjS6l3Rg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LOADING THE MODEL\n"
      ],
      "metadata": {
        "id": "e7zVFC6NlxXl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pre-trained Whisper model and processor\n",
        "feature_extractor = WhisperFeatureExtractor.from_pretrained(\"/content/tamilnew2\")\n",
        "\n",
        "# - Load Tokenizer: WhisperTokenizer\n",
        "tokenizer = WhisperTokenizer.from_pretrained(\"/content/tamilnew2\")\n",
        "\n",
        "processor = WhisperProcessor.from_pretrained(\"/content/tamilnew2\")\n",
        "\n",
        "model = WhisperForConditionalGeneration.from_pretrained(\"/content/tamilnew2\")\n",
        "model.config.forced_decoder_ids = None\n",
        "model.config.suppress_tokens = []"
      ],
      "metadata": {
        "id": "lkKJoAoilyqJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LOADING THE DATASET"
      ],
      "metadata": {
        "id": "nfXXOASfl-9V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "audio_paths=[]\n",
        "transcriptions = []\n",
        "\n",
        "# Open the CSV file and read its contents\n",
        "with open('dup.csv', newline='', encoding='utf-8') as csvfile:\n",
        "    csv_reader = csv.reader(csvfile)\n",
        "    # Skip the header row if it exists\n",
        "    next(csv_reader, None)\n",
        "\n",
        "    # Iterate through rows and append values to lists\n",
        "    for row in csv_reader:\n",
        "        audio_paths.append(row[0])\n",
        "        transcriptions.append(row[1])\n",
        "\n",
        "print(\"Column 1:\", audio_paths)\n",
        "print(\"Column 2:\", transcriptions)"
      ],
      "metadata": {
        "id": "DLvgqhSemBJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PROCESSING THE DATASET"
      ],
      "metadata": {
        "id": "bB8EMBfwmEhp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Process audio files and transcriptions\n",
        "inputs = processor((torchaudio.load(audio_paths) for path in audio_paths), return_tensors=\"pt\", padding=True, truncation=True)\n",
        "# inputs = processor(audio_paths, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "labels = processor(transcriptions, return_tensors=\"pt\", padding=True, truncation=True)[\"input_ids\"]\n",
        "\n",
        "# Create a DataLoader\n",
        "dataset = TensorDataset(inputs[\"input_values\"].to(device), inputs[\"attention_mask\"].to(device), labels.to(device))\n",
        "dataloader = DataLoader(dataset, batch_size=4, shuffle=True)\n"
      ],
      "metadata": {
        "id": "jnmkbm1bmGDO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SETTING UP OPTIMIZER AND SCHEDULER"
      ],
      "metadata": {
        "id": "LtDpbpgsmIzy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up optimizer and scheduler\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.9)\n"
      ],
      "metadata": {
        "id": "TrylVRgtmM2Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "FINETUNING THE MODEL"
      ],
      "metadata": {
        "id": "HwsBwC_ymO7J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fine-tune the model\n",
        "num_epochs = 3\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch in tqdm(dataloader, desc=f\"Epoch {epoch + 1}\"):\n",
        "        inputs = {\"input_values\": batch[0].to(device), \"attention_mask\": batch[1].to(device), \"labels\": batch[2].to(device)}\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(**inputs)\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    # Print average loss for the epoch\n",
        "    print(f\"Average Loss: {total_loss / len(dataloader)}\")\n",
        "\n",
        "    # Adjust learning rate\n",
        "    scheduler.step()\n"
      ],
      "metadata": {
        "id": "2ChvBoyemSTG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SAVING THE MODEL"
      ],
      "metadata": {
        "id": "u9Y7HF0vmUbC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the fine-tuned model\n",
        "model.save_pretrained(\"fine_tuned_whisper_model\")\n",
        "processor.save_pretrained(\"fine_tuned_whisper_model\")"
      ],
      "metadata": {
        "id": "xljJgna8mWi3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}